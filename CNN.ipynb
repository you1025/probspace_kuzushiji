{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from time import gmtime, strftime\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "def make_tensorboard(set_dir_name=\"\"):\n",
    "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S#\", gmtime())\n",
    "    directory_name = tictoc\n",
    "    log_dir = \"{}_{}\".format(set_dir_name, directory_name)\n",
    "    os.mkdir(log_dir)\n",
    "    tensorboard = TensorBoard(log_dir=log_dir)\n",
    "    \n",
    "    return tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 10s 209us/sample - loss: 0.9449 - acc: 0.6870 - val_loss: 0.3335 - val_acc: 0.8988\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 10s 202us/sample - loss: 0.3822 - acc: 0.8801 - val_loss: 0.2086 - val_acc: 0.9348\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.2681 - acc: 0.9170 - val_loss: 0.1481 - val_acc: 0.9540\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.2108 - acc: 0.9355 - val_loss: 0.1181 - val_acc: 0.9632\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.1746 - acc: 0.9469 - val_loss: 0.1068 - val_acc: 0.9675\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.1504 - acc: 0.9538 - val_loss: 0.0936 - val_acc: 0.9711\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.1310 - acc: 0.9598 - val_loss: 0.0864 - val_acc: 0.9736\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.1220 - acc: 0.9622 - val_loss: 0.0766 - val_acc: 0.9785\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.1051 - acc: 0.9670 - val_loss: 0.0730 - val_acc: 0.9796\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.1020 - acc: 0.9682 - val_loss: 0.0681 - val_acc: 0.9811\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0942 - acc: 0.9700 - val_loss: 0.0656 - val_acc: 0.9810\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0851 - acc: 0.9728 - val_loss: 0.0610 - val_acc: 0.9828\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0796 - acc: 0.9753 - val_loss: 0.0584 - val_acc: 0.9842\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0711 - acc: 0.9771 - val_loss: 0.0589 - val_acc: 0.9830\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0702 - acc: 0.9776 - val_loss: 0.0580 - val_acc: 0.9836\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0664 - acc: 0.9784 - val_loss: 0.0558 - val_acc: 0.9840\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0545 - val_acc: 0.9843\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0556 - acc: 0.9818 - val_loss: 0.0544 - val_acc: 0.9842\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0546 - acc: 0.9823 - val_loss: 0.0522 - val_acc: 0.9854\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0520 - acc: 0.9827 - val_loss: 0.0514 - val_acc: 0.9852\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 10s 202us/sample - loss: 0.0477 - acc: 0.9842 - val_loss: 0.0503 - val_acc: 0.9864\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0446 - acc: 0.9857 - val_loss: 0.0528 - val_acc: 0.9862\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0429 - acc: 0.9861 - val_loss: 0.0509 - val_acc: 0.9857\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0439 - acc: 0.9849 - val_loss: 0.0488 - val_acc: 0.9857\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0396 - acc: 0.9866 - val_loss: 0.0486 - val_acc: 0.9869\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0379 - acc: 0.9873 - val_loss: 0.0500 - val_acc: 0.9861\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0366 - acc: 0.9878 - val_loss: 0.0502 - val_acc: 0.9868\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0376 - acc: 0.9877 - val_loss: 0.0489 - val_acc: 0.9870\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0344 - acc: 0.9884 - val_loss: 0.0464 - val_acc: 0.9881\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0314 - acc: 0.9896 - val_loss: 0.0476 - val_acc: 0.9877\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0318 - acc: 0.9891 - val_loss: 0.0477 - val_acc: 0.9878\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0327 - acc: 0.9889 - val_loss: 0.0451 - val_acc: 0.9876\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0295 - acc: 0.9904 - val_loss: 0.0451 - val_acc: 0.9877\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0278 - acc: 0.9907 - val_loss: 0.0472 - val_acc: 0.9874\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0250 - acc: 0.9914 - val_loss: 0.0498 - val_acc: 0.9881\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0275 - acc: 0.9906 - val_loss: 0.0473 - val_acc: 0.9870\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0254 - acc: 0.9917 - val_loss: 0.0487 - val_acc: 0.9875\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0271 - acc: 0.9907 - val_loss: 0.0467 - val_acc: 0.9877\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 10s 201us/sample - loss: 0.0250 - acc: 0.9915 - val_loss: 0.0461 - val_acc: 0.9880\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 10s 201us/sample - loss: 0.0216 - acc: 0.9925 - val_loss: 0.0480 - val_acc: 0.9882\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0247 - acc: 0.9914 - val_loss: 0.0450 - val_acc: 0.9874\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0218 - acc: 0.9924 - val_loss: 0.0472 - val_acc: 0.9880\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0206 - acc: 0.9926 - val_loss: 0.0473 - val_acc: 0.9879\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0453 - val_acc: 0.9887\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0210 - acc: 0.9928 - val_loss: 0.0446 - val_acc: 0.9887\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0198 - acc: 0.9930 - val_loss: 0.0447 - val_acc: 0.9890\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0185 - acc: 0.9939 - val_loss: 0.0459 - val_acc: 0.9890\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0201 - acc: 0.9933 - val_loss: 0.0454 - val_acc: 0.9888\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 10s 198us/sample - loss: 0.0191 - acc: 0.9937 - val_loss: 0.0476 - val_acc: 0.9877\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 10s 199us/sample - loss: 0.0176 - acc: 0.9942 - val_loss: 0.0473 - val_acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f535530fa90>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# Data Load\n",
    "X_train = np.load(\"data/kmnist-train-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "y_train = np.load(\"data/kmnist-train-labels.npz\")[\"arr_0\"].astype(np.int32)\n",
    "X_test = np.load(\"data/kmnist-test-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "\n",
    "# Cleansing\n",
    "X_train_scaled  = X_train.reshape(60000, 28, 28, 1) / 255\n",
    "X_test_scaled   = X_test.reshape(10000, 28, 28, 1)  / 255\n",
    "Y_train_dummied = np_utils.to_categorical(y_train, 10)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        input_shape = (28, 28, 1),\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(units = 512, activation = \"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD(),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    Y_train_dummied,\n",
    "    batch_size = 32,\n",
    "    epochs = 50,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [\n",
    "        make_tensorboard(set_dir_name = \"tensorboards/Keras_Kuzushiji_V1\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9975\n"
     ]
    }
   ],
   "source": [
    "train_predicts = np.array([ np.argmax(probs) for probs in model.predict(X_train_scaled) ])\n",
    "train_accuracy = np.mean(train_predicts == y_train)\n",
    "print(\"Train Accuracy: {:.4}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 1.4069 - acc: 0.5047 - val_loss: 0.4511 - val_acc: 0.8643\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.4872 - acc: 0.8446 - val_loss: 0.2350 - val_acc: 0.9276\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 11s 233us/sample - loss: 0.3275 - acc: 0.8982 - val_loss: 0.1789 - val_acc: 0.9482\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.2487 - acc: 0.9223 - val_loss: 0.1370 - val_acc: 0.9557\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.2006 - acc: 0.9390 - val_loss: 0.1138 - val_acc: 0.9634\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1732 - acc: 0.9462 - val_loss: 0.0949 - val_acc: 0.9721\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1533 - acc: 0.9524 - val_loss: 0.0856 - val_acc: 0.9748\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1320 - acc: 0.9593 - val_loss: 0.0764 - val_acc: 0.9776\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1218 - acc: 0.9627 - val_loss: 0.0722 - val_acc: 0.9793\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1105 - acc: 0.9651 - val_loss: 0.0662 - val_acc: 0.9804\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.1018 - acc: 0.9683 - val_loss: 0.0638 - val_acc: 0.9810\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0897 - acc: 0.9724 - val_loss: 0.0582 - val_acc: 0.9826\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 11s 235us/sample - loss: 0.0846 - acc: 0.9734 - val_loss: 0.0530 - val_acc: 0.9844\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0807 - acc: 0.9746 - val_loss: 0.0536 - val_acc: 0.9843\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0745 - acc: 0.9762 - val_loss: 0.0516 - val_acc: 0.9852\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0687 - acc: 0.9777 - val_loss: 0.0486 - val_acc: 0.9860\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0653 - acc: 0.9795 - val_loss: 0.0488 - val_acc: 0.9865\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0614 - acc: 0.9806 - val_loss: 0.0459 - val_acc: 0.9872\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 11s 233us/sample - loss: 0.0598 - acc: 0.9812 - val_loss: 0.0463 - val_acc: 0.9863\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0561 - acc: 0.9820 - val_loss: 0.0445 - val_acc: 0.9872\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0532 - acc: 0.9836 - val_loss: 0.0406 - val_acc: 0.9884\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0511 - acc: 0.9835 - val_loss: 0.0414 - val_acc: 0.9881\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0462 - acc: 0.9851 - val_loss: 0.0409 - val_acc: 0.9887\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0443 - acc: 0.9860 - val_loss: 0.0392 - val_acc: 0.9888\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0444 - acc: 0.9854 - val_loss: 0.0384 - val_acc: 0.9891\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0426 - acc: 0.9865 - val_loss: 0.0396 - val_acc: 0.9889\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0397 - acc: 0.9870 - val_loss: 0.0408 - val_acc: 0.9886\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0402 - acc: 0.9871 - val_loss: 0.0401 - val_acc: 0.9882\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 11s 235us/sample - loss: 0.0367 - acc: 0.9882 - val_loss: 0.0398 - val_acc: 0.9893\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 11s 233us/sample - loss: 0.0362 - acc: 0.9877 - val_loss: 0.0385 - val_acc: 0.9896\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0334 - acc: 0.9885 - val_loss: 0.0366 - val_acc: 0.9893\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0336 - acc: 0.9889 - val_loss: 0.0378 - val_acc: 0.9892\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0307 - acc: 0.9901 - val_loss: 0.0383 - val_acc: 0.9891\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0298 - acc: 0.9901 - val_loss: 0.0382 - val_acc: 0.9898\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0281 - acc: 0.9910 - val_loss: 0.0370 - val_acc: 0.9902\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0352 - val_acc: 0.9903\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0283 - acc: 0.9906 - val_loss: 0.0370 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0281 - acc: 0.9909 - val_loss: 0.0366 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0340 - val_acc: 0.9904\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0262 - acc: 0.9914 - val_loss: 0.0373 - val_acc: 0.9902\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0252 - acc: 0.9914 - val_loss: 0.0359 - val_acc: 0.9905\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0235 - acc: 0.9922 - val_loss: 0.0373 - val_acc: 0.9905\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0347 - val_acc: 0.9908\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0222 - acc: 0.9925 - val_loss: 0.0348 - val_acc: 0.9898\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0231 - acc: 0.9927 - val_loss: 0.0355 - val_acc: 0.9904\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 11s 236us/sample - loss: 0.0217 - acc: 0.9926 - val_loss: 0.0353 - val_acc: 0.9905\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0210 - acc: 0.9932 - val_loss: 0.0347 - val_acc: 0.9908\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0203 - acc: 0.9930 - val_loss: 0.0345 - val_acc: 0.9906\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0381 - val_acc: 0.9900\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0332 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f540ab39128>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# Data Load\n",
    "X_train = np.load(\"data/kmnist-train-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "y_train = np.load(\"data/kmnist-train-labels.npz\")[\"arr_0\"].astype(np.int32)\n",
    "X_test = np.load(\"data/kmnist-test-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "\n",
    "# Cleansing\n",
    "X_train_scaled  = X_train.reshape(60000, 28, 28, 1) / 255\n",
    "X_test_scaled   = X_test.reshape(10000, 28, 28, 1)  / 255\n",
    "Y_train_dummied = np_utils.to_categorical(y_train, 10)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        input_shape = (28, 28, 1),\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(units = 512, activation = \"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD(),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    Y_train_dummied,\n",
    "    batch_size = 32,\n",
    "    epochs = 50,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [\n",
    "        make_tensorboard(set_dir_name = \"tensorboards/Keras_Kuzushiji_V1\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.998\n"
     ]
    }
   ],
   "source": [
    "train_predicts = np.array([ np.argmax(probs) for probs in model.predict(X_train_scaled) ])\n",
    "train_accuracy = np.mean(train_predicts == y_train)\n",
    "print(\"Train Accuracy: {:.4}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 17s 344us/sample - loss: 2.2938 - acc: 0.1287 - val_loss: 2.1839 - val_acc: 0.3563\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 1.1482 - acc: 0.6073 - val_loss: 0.4446 - val_acc: 0.8578\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 15s 312us/sample - loss: 0.4866 - acc: 0.8453 - val_loss: 0.2522 - val_acc: 0.9208\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.3287 - acc: 0.8976 - val_loss: 0.1833 - val_acc: 0.9420\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 15s 313us/sample - loss: 0.2493 - acc: 0.9231 - val_loss: 0.1446 - val_acc: 0.9550\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.1997 - acc: 0.9380 - val_loss: 0.1192 - val_acc: 0.9629\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.1642 - acc: 0.9494 - val_loss: 0.0998 - val_acc: 0.9688\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.1434 - acc: 0.9570 - val_loss: 0.0925 - val_acc: 0.9717\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.1237 - acc: 0.9615 - val_loss: 0.0800 - val_acc: 0.9750\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.1123 - acc: 0.9665 - val_loss: 0.0718 - val_acc: 0.9793\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.1015 - acc: 0.9689 - val_loss: 0.0749 - val_acc: 0.9785\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0912 - acc: 0.9717 - val_loss: 0.0720 - val_acc: 0.9788\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0817 - acc: 0.9746 - val_loss: 0.0638 - val_acc: 0.9812\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0754 - acc: 0.9770 - val_loss: 0.0628 - val_acc: 0.9815\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 15s 313us/sample - loss: 0.0715 - acc: 0.9778 - val_loss: 0.0565 - val_acc: 0.9836\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0673 - acc: 0.9792 - val_loss: 0.0568 - val_acc: 0.9835\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 15s 314us/sample - loss: 0.0602 - acc: 0.9810 - val_loss: 0.0565 - val_acc: 0.9837\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0576 - acc: 0.9815 - val_loss: 0.0553 - val_acc: 0.9847\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0504 - val_acc: 0.9854\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0514 - acc: 0.9842 - val_loss: 0.0513 - val_acc: 0.9858\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0473 - acc: 0.9851 - val_loss: 0.0502 - val_acc: 0.9862\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0501 - val_acc: 0.9856\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0413 - acc: 0.9870 - val_loss: 0.0513 - val_acc: 0.9862\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0397 - acc: 0.9873 - val_loss: 0.0538 - val_acc: 0.9850\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0374 - acc: 0.9880 - val_loss: 0.0474 - val_acc: 0.9877\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0355 - acc: 0.9886 - val_loss: 0.0473 - val_acc: 0.9871\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 15s 312us/sample - loss: 0.0350 - acc: 0.9890 - val_loss: 0.0497 - val_acc: 0.9865\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0337 - acc: 0.9896 - val_loss: 0.0463 - val_acc: 0.9880\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 15s 313us/sample - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0439 - val_acc: 0.9883\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0285 - acc: 0.9905 - val_loss: 0.0480 - val_acc: 0.9886\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0481 - val_acc: 0.9875\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0264 - acc: 0.9917 - val_loss: 0.0456 - val_acc: 0.9883\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0269 - acc: 0.9912 - val_loss: 0.0458 - val_acc: 0.9877\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.0471 - val_acc: 0.9883\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0237 - acc: 0.9921 - val_loss: 0.0464 - val_acc: 0.9881\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0226 - acc: 0.9929 - val_loss: 0.0472 - val_acc: 0.9882\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0537 - val_acc: 0.9872\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0214 - acc: 0.9931 - val_loss: 0.0437 - val_acc: 0.9884\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 15s 313us/sample - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0483 - val_acc: 0.9881\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0191 - acc: 0.9939 - val_loss: 0.0497 - val_acc: 0.9881\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 15s 314us/sample - loss: 0.0173 - acc: 0.9948 - val_loss: 0.0496 - val_acc: 0.9887\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0188 - acc: 0.9941 - val_loss: 0.0488 - val_acc: 0.9883\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0478 - val_acc: 0.9887\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0165 - acc: 0.9946 - val_loss: 0.0509 - val_acc: 0.9893\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0166 - acc: 0.9946 - val_loss: 0.0495 - val_acc: 0.9890\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0171 - acc: 0.9946 - val_loss: 0.0516 - val_acc: 0.9892\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0151 - acc: 0.9949 - val_loss: 0.0501 - val_acc: 0.9893\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0438 - val_acc: 0.9893\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0477 - val_acc: 0.9892\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 15s 310us/sample - loss: 0.0137 - acc: 0.9953 - val_loss: 0.0459 - val_acc: 0.9893\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 15s 313us/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.0452 - val_acc: 0.9902\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 15s 311us/sample - loss: 0.0132 - acc: 0.9956 - val_loss: 0.0488 - val_acc: 0.9898\n",
      "Epoch 53/100\n",
      "15136/48000 [========>.....................] - ETA: 9s - loss: 0.0117 - acc: 0.9966"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "# Data Load\n",
    "X_train = np.load(\"data/kmnist-train-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "y_train = np.load(\"data/kmnist-train-labels.npz\")[\"arr_0\"].astype(np.int32)\n",
    "X_test = np.load(\"data/kmnist-test-imgs.npz\")[\"arr_0\"].astype(np.int32)\n",
    "\n",
    "# Cleansing\n",
    "X_train_scaled  = X_train.reshape(60000, 28, 28, 1) / 255\n",
    "X_test_scaled   = X_test.reshape(10000, 28, 28, 1)  / 255\n",
    "Y_train_dummied = np_utils.to_categorical(y_train, 10)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Conv2D(\n",
    "        input_shape = (28, 28, 1),\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 32,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 64,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 128,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    Conv2D(\n",
    "        filters = 256,\n",
    "        kernel_size = (3, 3),\n",
    "        strides = (1, 1),\n",
    "        padding = \"same\",\n",
    "        activation = \"relu\"\n",
    "    ),\n",
    "    MaxPooling2D(pool_size = (2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(units = 512, activation = \"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units = 10, activation = \"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = SGD(),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    Y_train_dummied,\n",
    "    batch_size = 32,\n",
    "    epochs = 100,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [\n",
    "        make_tensorboard(set_dir_name = \"tensorboards/Keras_Kuzushiji_V1\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "JST = timezone(timedelta(hours = 9))\n",
    "str_now = datetime.now(JST).strftime(\"%Y%m%d%H%M%S\")\n",
    "filename = \"predicts_{}.txt\".format(str_now)\n",
    "\n",
    "predicts  = np.array([ np.argmax(probs) for probs in model.predict(X_test_scaled) ])\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"ImageId\": np.arange(1, len(predicts) + 1),\n",
    "        \"Label\": predicts\n",
    "    }\n",
    ").to_csv(os.path.join(\"results\", filename), index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
